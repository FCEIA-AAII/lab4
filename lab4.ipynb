{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - Predicción de supervivientes del Titanic.\n",
    "\n",
    "El objetivo de este laboratorio es entrenar un clasificador binario para el dataset de la siguiente competición:\n",
    "\n",
    "https://www.kaggle.com/c/titanic/overview\n",
    "\n",
    "Se busca que la salida del modelo sea la probabilidad de supervivencia del pasajero segun los datos de entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FCEIA-AAII/lab4/blob/main/lab4.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno.\n",
    "\n",
    "Si no estamos parados en el repo, clonar y cd al repo. Esto nos permite usar el mismo notebook tanto local como en Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "REPO_NAME = \"lab4\"\n",
    "if REPO_NAME not in os.getcwd():\n",
    "  if not os.path.exists(REPO_NAME):\n",
    "    !git clone https://github.com/FCEIA-AAII/{REPO_NAME}.git\n",
    "  os.chdir(REPO_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecer GPU por defecto en caso de estar disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar para que TensorFlow utilice la GPU por defecto\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Configurar para que TensorFlow asigne memoria dinámicamente\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # Especificar la GPU por defecto\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Manejar error\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataset\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspeccionamos cada columna del dataset para entender su significado y valores posibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train_df.columns\n",
    "\n",
    "for col in cols:\n",
    "    print(\"--------------------\")\n",
    "    print(\"Columna: \", col)\n",
    "    print(\"Cantidad de valores nulos: \", train_df[col].isnull().sum())\n",
    "    print(\"Cantidad de valores únicos: \", train_df[col].nunique())\n",
    "    print(\"Tipo de dato: \", train_df[col].dtype)\n",
    "    # Si no es numérica, continuar con la siguiente columna\n",
    "    if train_df[col].dtype == \"object\":\n",
    "        print(\"--------------------\")\n",
    "        continue\n",
    "    # Si es una columna categórica, mostrar la cantidad de veces que aparece cada valor\n",
    "    if train_df[col].nunique() < 10:\n",
    "        print(\"Valores únicos: \", train_df[col].unique())\n",
    "        print(\"Cantidad de veces que aparece cada valor: \", train_df[col].value_counts())\n",
    "    else:\n",
    "        # Si es una columna numérica, mostramos media, desvío estándar, mínimo, máximo...\n",
    "        print(\"Media: \", train_df[col].mean())\n",
    "        print(\"Desvío estándar: \", train_df[col].std())\n",
    "        print(\"Mínimo: \", train_df[col].min())\n",
    "        print(\"Máximo: \", train_df[col].max())\n",
    "    print(\"--------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos un primer modelo con un subset de features `[\"Pclass\", \"sex\", \"Age\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino un diccionario para definir el tipo de dato de cada columna\n",
    "column_types = {\n",
    "    \"Pclass\": \"categoric\",\n",
    "    \"Sex\": \"categoric\",\n",
    "    \"Age\": \"numeric\",\n",
    "}\n",
    "\n",
    "# Diccionario para almacenar media y desvío estándar de las columnas numéricas.\n",
    "# Me va a servir para realizar predicciones en el futuro.\n",
    "numeric_stats = {}\n",
    "\n",
    "# Diccionario para almacenar los valores únicos de las columnas categóricas.\n",
    "# Me va a servir para realizar predicciones en el futuro.\n",
    "categoric_values = {}\n",
    "\n",
    "preprocessed_train_df = pd.DataFrame()\n",
    "preprocessed_test_df = pd.DataFrame()\n",
    "\n",
    "# Preprocesamiento del set de entrenamiento\n",
    "for col in column_types.keys():\n",
    "    if column_types[col] == \"categoric\":\n",
    "        num_classes = train_df[col].nunique()\n",
    "        # Obtengo el one-hot encoding de la columna\n",
    "        one_hot = pd.get_dummies(train_df[col], prefix=col, dtype=np.float32)\n",
    "        # Agrego las columnas al dataset preprocesado\n",
    "        preprocessed_train_df = pd.concat([preprocessed_train_df, one_hot], axis=1)\n",
    "        # Almaceno los valores únicos\n",
    "        categoric_values[col] = train_df[col].unique()\n",
    "    else:\n",
    "        # Normalizo la columna\n",
    "        preprocessed_train_df[col] = (train_df[col] - train_df[col].mean()) / train_df[col].std()\n",
    "        # Almaceno media y desvío estándar\n",
    "        numeric_stats[col] = {\n",
    "            \"mean\": train_df[col].mean(),\n",
    "            \"std\": train_df[col].std()\n",
    "        }\n",
    "\n",
    "# Agrergo la columna \"Survived\" al dataset preprocesado\n",
    "preprocessed_train_df[\"Survived\"] = train_df[\"Survived\"]\n",
    "\n",
    "# Muestro las primeras filas del dataset preprocesado\n",
    "print(preprocessed_train_df.head())\n",
    "\n",
    "# Drop nan values\n",
    "preprocessed_train_df = preprocessed_train_df.dropna()\n",
    "\n",
    "# Defino los vectores X_train, y_train, X_test e y_test\n",
    "X_train = preprocessed_train_df.drop(\"Survived\", axis=1).values.astype(np.float32)\n",
    "y_train = preprocessed_train_df[\"Survived\"].values.astype(np.float32)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino un primer modelo y lo entreno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
